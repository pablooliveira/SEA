%% -*- Lecture -*-

\synctex=1
\documentclass[11pt]{beamer}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}


\usepackage{lectureb}
\usetheme{CambridgeUS}
\topic{Concurrency}

\begin{document}
\maketitle

\begin{slide}{Rappel : API des threads}
\itms{
   \item \texttt{tid thread\_create (void (*fn) (void *), \rlap{void
           *arg);}}
  \ittms{
    \item Crée un nouveau thread qui appelle \texttt{fn} avec \texttt{arg}
  }
  \item \texttt{void thread\_exit ();}
  \item \texttt{void thread\_join (tid thread);}
  \item L'exécution de plusieurs threads est entrelacée
  \item Peut avoir des threads \emph{\Red{non-préemptifs}}:
  \ittms{
    \item Un thread s'exécute
      exclusivement jusqu'à ce qu'il fasse un appel bloquant.
  }
  \item Ou des threads \emph{\Red{préemptifs}}:
  \ittms{
    \item Peut basculer vers
      un autre thread entre deux instructions quelconques.
  }
  \item L'utilisation de plusieurs CPU est intrinsèquement préemptive
  \ittms{
    \item Même si on ne retire pas le $CPU_0$ au thread $T$, un autre
      thread sur le $CPU_1$ peut s'exécuter entre deux instructions de
      $T$.
  }
%  \item Threads may run simultaneously
%  \ittms{
%    \item E.g., \texttt{create (p1, NULL); create (p2, NULL);}
%    \item \texttt{p1} and \texttt{p2} run interleaved or concurrently
%  }
%  \item Threads have same address space
%  \ittms{
%    \item Usually share some memory locations between threads
%    \item Otherwise, could just have used processes
%  }
%  \item Sharing + Concurrency can lead to unexpected results
}
\end{slide}

\begin{slide}{\hypertarget{prog-a}{Programme A}}
\begin{ccode}
  int flag1 = 0, flag2 = 0;

  void p1 (void *ignored) {
    flag1 = 1;
    if (!flag2) { critical_section_1 (); }
  }

  void p2 (void *ignored) {
    flag2 = 1;
    if (!flag1) { critical_section_2 (); }
  }

  int main () {
    tid id = thread_create (p1, NULL);
    p2 (); thread_join (id);
  }
\end{ccode}
\itms{
  \item Les deux sections critiques peuvent-elles s'exécuter ?
}
\end{slide}

\begin{slide}{\hypertarget{prog-b}{Programme B}}
\begin{ccode}
  int data = 0, ready = 0;

  void p1 (void *ignored) {
    data = 2000;
    ready = 1;
  }

  void p2 (void *ignored) {
    while (!ready)
      ;
    use (data);
  }

  int main () { ... }
\end{ccode}
\itms{
  \item \texttt{use} peut-elle être appelée avec la valeur 0 ?
}
\end{slide}

\begin{slide}{Réponses correctes}
\itms{
  \item Programme A:  Je ne sais pas
  \item Programme B:  Je ne sais pas
  \item Pourquoi ?
  \ittms{
    \item \Red{Cela dépend de votre matériel}
    \item S'il fournit la \emph{cohérence séquentielle},
      alors les réponses sont toutes Non
    \item Mais tout le matériel ne fournit pas la cohérence séquentielle
  }
}
\end{slide}

\begin{slide}{Cohérence Séquentielle}
\begin{itemize}
\item \textit{Cohérence séquentielle} : Le résultat de l'exécution est comme si toutes les opérations étaient exécutées dans un ordre séquentiel, et les opérations de chaque processeur se produisaient dans l'ordre spécifié par le programme.
\cref{sched/readings/sequential-consistency.pdf}{[Lamport]}
\item Se résume à deux exigences :
\begin{enumerate}
  \item Maintenir l' \textit{ordre du programme} sur les processeurs individuels
  \item Garantir l' \textit{atomicité d'écriture}
\end{enumerate}
\end{itemize}
\itms{
  \item Sans SC, plusieurs CPU peuvent être « pires » que des threads préemptifs
  \ittms{
    \item Peut voir des résultats qui ne peuvent se produire avec aucun entrelacement sur
      \rlap{1 CPU}
  }
  \item Pourquoi tout le matériel ne supporte-t-il pas la cohérence séquentielle ?
}
\end{slide}

\begin{slide}{SC empêche les optimisations matérielles}
\itms{
  \item Impossible de réordonner les opérations d'écriture se chevauchant
  \ittms{
    \item Fusion des écritures sur la même ligne de cache
  }
  \item Complique les lectures non bloquantes
  \ittms{
    \item Ex : préchargement spéculatif de \texttt{data}
    }
  \item Rend la cohérence de cache plus coûteuse
}
\end{slide}

\begin{slide}{SC empêche les optimisations du compilateur}
\itms{
  \item Déplacement de code
  \item Mise en cache de valeur dans un registre
  \ittms{
    \item Fusionne plusieurs chargements/stockages de la même adresse en une
      opération
%    \item E.g., \texttt{ready} flag in \hyperlink{prog-b}{Program B}
  }
  \item Élimination des sous-expressions communes
  \ittms{
    \item Pourrait causer moins de lectures d'un emplacement mémoire
  }
  \item Blocage de boucle
  \ittms{
    \item Réorganiser les boucles pour une meilleure performance du cache
  }
  \item Pipelining logiciel
  \ittms{
    \item Déplacer les instructions à travers les itérations d'une boucle pour chevaucher
      la latence d'instruction avec le coût de branchement
  }
}
\end{slide}

\begin{slide}{Cohérence x86
    [\href{http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf}{intel
            3a}, \S8.2]}
\itms{
  \item x86 supporte plusieurs modèles de cohérence/cache
  \ittms{
    \item Les registres MTRR (Memory Type Range Registers) spécifient la cohérence pour
      des plages de mémoire physique (ex : frame buffer)
    \item La table des attributs de page (PAT) permet le contrôle pour chaque page de 4K
  }
  \item Les choix incluent :
  \ittms{
    \item \textbf{WB}:  Mise en cache \emph{Write-back} (par défaut)
    \item \textbf{WT}:  Mise en cache \emph{Write-through} (toutes les écritures vont en
      mémoire)
    \item \textbf{UC}:  Non cachable (pour la mémoire de périphérique)
    \item \textbf{WC}:  Write-combining -- cohérence faible \& pas de
      mise en cache \\
      (utilisé pour les frame buffers, lors de l'envoi de beaucoup de données au GPU)
  }
}
\end{slide}


\defverbatim\rdownwr{
\small\openup-.5\jot
\begin{verbatim}
    volatile int flag1 = 0, flag2 = 0;
\end{verbatim}
\begin{verbatim}
    int p1 (void)               int p2 (void)
    {                           {
      register int f, g;          register int f, g;
      flag1 = 1;                  flag2 = 1;
      f = flag1;                  f = flag2;
      g = flag2;                  g = flag1;
      return 2*f + g;             return 2*f + g;
    }                           }
\end{verbatim}}

\begin{frame}
\frametitle{Cohérence WB x86}
\smallskip
\itms{
  \item Les vieux x86 (ex : 486, Pentium 1) avaient presque SC
  \ittms{
    \item Exception : une lecture pouvait se terminer avant une écriture antérieure à un
      emplacement différent
    \item Lequel des programmes
      \hyperlink{prog-a}{A},
      \hyperlink{prog-b}{B}, pourrait être affecté ?
      \quad \only<2>{\textsl{Juste A}}
  }
%\pause
  \item Les x86 plus récents permettent aussi à un CPU de lire ses propres écritures en avance
%  \ittms{
%    \item E.g., \emph{both} \texttt{p1} and \texttt{p2} can return 2: \\[1ex]
%    \item Older CPUs would wait at ``\texttt{f = \ldots}'' until store
%      complete
%  }
}
\end{frame}

\begin{slide}{Atomicité x86}
\itms{
  \item Le préfixe \texttt{lock} rend une instruction mémoire atomique
  \ittms{
    \item Verrouille généralement le bus pour la durée de l'instruction (coûteux !)
    \item Toutes les instructions lock sont totalement ordonnées
    \item Les autres instructions mémoire ne peuvent pas être réordonnées avec celles
      verrouillées
  }
  \item L'instruction \texttt{xchg} est toujours verrouillée (même sans préfixe)
  \item Des instructions barrières (\emph{fence}) spéciales peuvent empêcher le réordonnancement
  \ittms{
    \item \texttt{mfence} -- ne peut pas être réordonnée avec des lectures ou écritures
  }

}
\end{slide}

\begin{slide}{Supposer la cohérence séquentielle}
\itms{
  \item Point important : \Red{Connaissez votre modèle mémoire}
  \ittms{
    \item Particulièrement car les OS ont typiquement leur propre synchronisation
  }
  \item La plupart du code applicatif devrait éviter de dépendre du modèle mémoire
  \ittms{
    \item Obéissez à certaines règles, et le comportement devrait être identique à S.C.
  }
  \item Disons pour l'instant que nous avons la cohérence séquentielle
  %\item Later will see alpha which doesn't have SC
  \item Exemple de code concurrent : Producteur/Consommateur
  \ittms{
    \item \texttt{buffer} stocke \texttt{BUFFER\_SIZE} éléments
    \item \texttt{count} est le nombre d'emplacements utilisés
    \item \texttt{out} est le prochain emplacement vide à remplir (si existant)
    \item \texttt{in} est le plus ancien emplacement rempli à consommer (si existant)
  }
}
\end{slide}

\begin{frame}[fragile]
\medskip
\begin{smallccode}
     void producer (void *ignored) {
         for (;;) {
             item *nextProduced = produce_item ();
             while (count == BUFFER_SIZE)
                 /* ne rien faire */;
             buffer [in] = nextProduced;
             in = (in + 1) % BUFFER_SIZE;
             count++;
         }
     }

     void consumer (void *ignored) {
         for (;;) {
             while (count == 0)
                 /* ne rien faire */;
             item *nextConsumed =  buffer[out];
             out = (out + 1) % BUFFER_SIZE;
             count--;
             consume_item (nextConsumed);
         }
     }
\end{smallccode}
\itms{
  \item Qu'est-ce qui peut mal tourner ici ?
}
\end{frame}

\begin{slide}{\textit{Race Conditions}}
\itms{
  \item \texttt{count} peut avoir une mauvaise valeur
  \item Implémentation possible de \Blue{\texttt{count++}}
          et \Red{\texttt{count-{}-}}
}
{
\begin{tabular}{@{\qquad\qquad}l@{\qquad}l}
\Blue{register$\gets$count} &
\Red{register$\gets$count} \\
\Blue{register$\gets$register $+$ 1} &
\Red{register$\gets$register $-$ 1} \\
\Blue{count$\gets$register} &
\Red{count$\gets$register} \\
\end{tabular}}
\itms{
  \item Exécution possible (count un de moins que correct) :
}
\qquad\qquad \Blue{register$\gets$count} \\
\qquad\qquad \Blue{register$\gets$register $+$ 1} \\
\qquad\qquad \Red{register$\gets$count} \\
\qquad\qquad \Red{register$\gets$register $-$ 1} \\
\qquad\qquad \Blue{count$\gets$register} \\
\qquad\qquad \Red{count$\gets$register} \\
\end{slide}

\begin{slide}{\textit{Race Conditions} (suite)}
\itms{
  \item Quid d'une addition en une seule instruction ?
  \ittms{
    \item Ex : i386 permet l'instruction unique \Blue{\texttt{addl
    \$1,\_count}}
    \item Donc implémenter \texttt{count++/-{}-} avec une seule instruction
    \item Sommes-nous saufs maintenant ?
  }
\pause
  \item Pas atomique sur multiprocesseur !
  \ittms{
    \item Subira exactement la même \emph{race condition}
    \item Peut potentiellement rendre atomique avec le préfixe \texttt{lock}
    \item Mais \texttt{lock} très coûteux
    \item Le compilateur ne le générera pas, suppose que vous ne voulez pas la pénalité
  }
  %\item Note that without SC, even reads can be dangerous
  \item Besoin d'une solution au problème de \emph{section critique}
  \ittms{
    \item Placer \texttt{count++} et \texttt{count-{}-} en section critique
    \item Protéger les sections critiques de l'exécution concurrente
  }
}
\end{slide}

\begin{slide}{Propriétés désirées de la solution}
\itms{
  \item \emph{Exclusion mutuelle}
  \ittms{
    \item Seul un thread peut être en section critique à la fois
  }
  \item \emph{Progrès}
  \ittms{
    \item Disons qu'aucun processus n'est actuellement en section critique (S.C.)
    %\item Threads trying to enter C.S. can't be blocked by those not trying
    \item Un des processus essayant d'entrer finira par entrer
  }
  \item \emph{Attente bornée}
  \ittms{
    \item Une fois qu'un thread $T$ commence à essayer d'entrer en section critique,
      il y a une borne sur le nombre de fois que d'autres threads entrent
  }
  \item Notez progrès vs.\ attente bornée
  \ittms{
    \item Si aucun thread ne peut entrer en S.C., pas de progrès
    \item Si le thread $A$ attend pour entrer en S.C. pendant que $B$
      quitte et rentre dans la S.C. de façon répétée \emph{ad infinitum}, pas d'
      attente bornée
  }
}
\end{slide}

%\begin{slide}{Peterson's solution}
%\itms{
%  \item Still assuming sequential consistency
%  \item Assume two threads, $T_0$ and $T_1$
%  \item Variables
%  \ittms{
%    \item \texttt{int not\_turn;} {\color{comment}-- not this thread's
%      turn to enter C.S.}
%    \item \texttt{bool wants[2];} {\color{comment}-- \texttt{wants[i]}
%      indicates if $T_i$ wants to enter C.S.}
%  }
%  \item Code:
%}
%\begin{ccode}
% for (;;) { /* assume i is thread number (0 or 1) */
%   wants[i] = true;
%   not_turn = i;
%   while (wants[1-i] && not_turn == i)
%     /* other thread wants in and not our turn, so loop */;
%   Critical_section ();
%   wants[i] = false;
%   Remainder_section ();
% }
%\end{ccode}
%\end{slide}
%
%\begin{slide}{Does Peterson's solution work?}
%\begin{smallccode}
%      for (;;) { /* code in thread i */
%        wants[i] = true;
%        not_turn = i;
%        while (wants[1-i] && not_turn == i)
%          /* other thread wants in and not our turn, so loop */;
%        Critical_section ();
%        wants[i] = false;
%        Remainder_section ();
%      }
%\end{smallccode}
%\itms{
%  \item Mutual exclusion -- can't both be in C.S.
%  \ittms{
%    \item Would mean \texttt{wants[0] == wants[1] == true}, \\
%          so \texttt{not\_turn} would have blocked one thread from C.S.
%  }
%  \item Progress -- If $T_{1-i}$ not in C.S., can't block $T_i$
%  \ittms{
%    \item Means \texttt{wants[1-i] == false}, so $T_i$ won't loop
%  }
%  \item Bounded waiting -- similar argument to progress
%  \ittms{
%    \item If $T_i$ wants lock and $T_{1-i}$ tries to re-enter,
%      $T_{1-i}$ will set \\
%      \texttt{not\_turn = 1 - i}, allowing $T_i$ in
%  }
%}
%\end{slide}

\begin{slide}{Mutex}
\itms{
  \item Doit s'adapter au modèle mémoire de la machine si non S.C.
  \ittms{
    \item Idéalement, vous voulez que votre code s'exécute partout
  }
  \item Vouloir isoler le programmeur de l'implémentation des primitives
    de synchronisation
  \item Les bibliothèques de threads fournissent typiquement des \emph{mutex} : \\
    \texttt{void mutex\_init (mutex\_t *m, \ldots);} \\
    \texttt{void mutex\_lock (mutex\_t *m);} \\
    \texttt{int mutex\_trylock (mutex\_t *m);} \\
    \texttt{void mutex\_unlock (mutex\_t *m);} \\
  \ittms{
    \item Un seul thread acquiert \texttt{m} à la fois, les autres attendent
  }
}
\end{slide}

\begin{slide}{Contrat de l'API des threads}
\itms{
  \item \Red{Toutes les données globales doivent être protégées par un mutex !}
  \ittms{
    \item Global = accédé par plus d'un thread, au moins une
      écriture
    \item L'exception est l'initialisation, avant d'être exposé aux
      autres threads
    \item C'est la responsabilité de l'auteur de l'application
  }
  \item Si vous utilisez les mutex correctement, le comportement devrait être
    indiscernable de la cohérence séquentielle
  \ittms{
    \item C'est la responsabilité de la bibliothèque de threads (\&
      compilateur)
    \item Le mutex est cassé si vous l'utilisez correctement et ne voyez pas SC
  }
  \item Les noyaux d'OS ont aussi besoin de synchronisation
  \ittms{
    \item Peut ressembler ou non à des mutex
  }
}
\end{slide}

\begin{slide}{Même concept, plusieurs noms}
\itms{
  \item API de threads niveau application la plus populaire :  \emph{pthreads}
  \ittms{
    \item Les noms de fonctions dans ce cours sont tous basés sur \emph{pthreads}
    \item Ajoutez juste le préfixe \texttt{pthread\_}
    \item E.g., \texttt{pthread\_mutex\_t},
      \texttt{pthread\_mutex\_lock}, \ldots
  }
}
\end{slide}


\begin{slide}{Producteur amélioré}
\begin{ccode}[classoffset=2,morekeywords={mutex_lock,mutex_unlock},keywordstyle=\color{red}]
mutex_t mutex = MUTEX_INITIALIZER;

void producer (void *ignored) {
    for (;;) {
        item *nextProduced = produce_item ();

        mutex_lock (&mutex);
        while (count == BUFFER_SIZE) {
          mutex_unlock (&mutex);  /* <--- Pourquoi ? */
          thread_yield ();
          mutex_lock (&mutex);
        }

        buffer [in] = nextProduced;
        in = (in + 1) % BUFFER_SIZE;
        count++;
        mutex_unlock (&mutex);
    }
}
\end{ccode}
\end{slide}

\begin{slide}{Consommateur amélioré}
\begin{ccode}[classoffset=2,morekeywords={mutex_lock,mutex_unlock},keywordstyle=\color{red}]
void consumer (void *ignored) {
    for (;;) {
        mutex_lock (&mutex);
        while (count == 0) {
          mutex_unlock (&mutex);
          thread_yield ();
          mutex_lock (&mutex);
        }

        item *nextConsumed =  buffer[out];
        out = (out + 1) % BUFFER_SIZE;
        count--;
        mutex_unlock (&mutex);

        consume_item (nextConsumed);
    }
}
\end{ccode}
\end{slide}

\begin{slide}{Variables de condition}
\itms{
  \item L'attente active dans l'application est une mauvaise idée
  \ittms{
    \item Le thread consomme du CPU même quand il ne peut pas progresser
    \item Ralentit inutilement les autres threads et processus
  }
  \item Mieux vaut informer l'ordonnanceur des threads qui peuvent s'exécuter
  \item Typiquement fait avec des \emph{variables de condition}
  \item \texttt{void cond\_init (cond\_t *, \ldots);}
  \ittms{
    \item Initialiser
  }
  \item \texttt{void cond\_wait (cond\_t *c, mutex\_t *m);}
  \ittms{
    \item Déverrouille atomiquement \texttt{m} et dort jusqu'à ce que \texttt{c} soit signalé
    \item Puis ré-acquiert \texttt{m} et reprend l'exécution
  }
  \item \texttt{void cond\_signal (cond\_t *c);} \\
        \texttt{void cond\_broadcast (cond\_t *c);}
  \ittms{
    \item Réveille un/tous les threads attendant sur \texttt{c}
  }
}
\end{slide}

\begin{slide}{Producteur amélioré}
\begin{ccode}[classoffset=2,morekeywords={cond_wait,cond_signal},keywordstyle=\color{red}]
mutex_t mutex = MUTEX_INITIALIZER;
cond_t nonempty = COND_INITIALIZER;
cond_t nonfull = COND_INITIALIZER;

void producer (void *ignored) {
    for (;;) {
        item *nextProduced = produce_item ();

        mutex_lock (&mutex);
        while (count == BUFFER_SIZE)
          cond_wait (&nonfull, &mutex);

        buffer [in] = nextProduced;
        in = (in + 1) % BUFFER_SIZE;
        count++;
        cond_signal (&nonempty);
        mutex_unlock (&mutex);
    }
}
\end{ccode}
\end{slide}

\begin{slide}{Consommateur amélioré}
\begin{ccode}[classoffset=2,morekeywords={cond_wait,cond_signal},keywordstyle=\color{red}]
void consumer (void *ignored) {
    for (;;) {
        mutex_lock (&mutex);
        while (count == 0)
          cond_wait (&nonempty, &mutex);

        item *nextConsumed =  buffer[out];
        out = (out + 1) % BUFFER_SIZE;
        count--;
        cond_signal (&nonfull);
        mutex_unlock (&mutex);

        consume_item (nextConsumed);
    }
}
\end{ccode}
\end{slide}

\begin{slide}{Revérifier les conditions}
\itms{
  \item Toujours revérifier la condition au réveil :
}
\vspace*{-.5\baselineskip}
\begin{ccode}
        `\Red{while}' (count == 0)  /* pas `\Red{if}' */
          cond_wait (&nonempty, &mutex);
\end{ccode}
\itms{
  \item Sinon, casse avec deux consommateurs
  \begin{itemize}
    \item Commence avec un buffer vide, puis :
  \end{itemize}
}
{\small\openup-1\jot
\halign{#\hfil \quad & \quad #\hfil \quad & \quad # \hfil \cr
\hfil \vrule width0pt depth 8pt{}$C_1$ & \hfil $C_2$ & $P$ \cr
\texttt{cond\_wait (\ldots);} & & {\texttt{mutex\_lock (\ldots);}}\cr
& & \hfil $\vdots$ \cr
& & \texttt{count++;} \cr
& & \texttt{cond\_signal (\ldots);} \cr
& {\texttt{mutex\_lock (\ldots);}} & \texttt{mutex\_unlock (\ldots);} \cr
& \texttt{if (count == 0)} & \cr
& \hfil $\vdots$ & \cr
& \emph{use} \texttt{buffer[out]} \ldots & \cr
& \texttt{count--;} & \cr
& \texttt{mutex\_unlock (\ldots);} & \cr
\noalign{\smallskip}
\multispan{3}
\emph{use} \texttt{buffer[out]} \ldots
    \Red{$\;\;\longleftarrow$ Pas d'éléments dans le buffer}\hfil\cr
%\texttt{\Red{count-{}-};} & & \cr
}}
\end{slide}


\defverbatim\condwomutex{
\begin{ccode}
             while (count == BUFFER_SIZE) {
               mutex_unlock (&mutex);
               cond_wait (&nonfull);
               mutex_lock (&mutex);
             }
\end{ccode}}

\defverbatim[colored]\condwomutexbug{
\small\openup-.17\baselineskip
{\color{comment}
\begin{verbatim}
   PRODUCER                        CONSUMER
\end{verbatim}
}
\begin{verbatim}
   while (count == BUFFER_SIZE)
     mutex_unlock (&mutex);
                                   mutex_lock (&mutex);
                                   ...
                                   count--;
                                   cond_signal (&nonfull);
     cond_wait (&nonfull);
\end{verbatim}
}

\begin{slide}{Variables de condition (suite)}
\itms{
  \item Pourquoi \texttt{cond\_wait} doit-elle à la fois relâcher le mutex \& dormir ?
  \item Pourquoi ne pas séparer les mutex et les variables de condition ?
}
\condwomutex
\begin{overprint}
\onslide<2->{
\itms{
  \item Peut finir bloqué en attente lors d'un mauvais entrelacement
}
\condwomutexbug
}
\end{overprint}
\end{slide}



\begin{slide}{Sémaphores
    \href{http://www.cs.utexas.edu/users/EWD/transcriptions/EWD01xx/EWD123.html}{[Dijkstra]}}
\itms{
  \item Un \emph{Sémaphore} est initialisé avec un entier $N$
  \item Fournit deux fonctions :
  \ittms{
    \item \texttt{sem\_wait (S)}\quad  (appelée à l'origine $P$)
    \item \texttt{sem\_signal (S)}\quad (appelée à l'origine $V$)
  }
  \item Garantit que \texttt{sem\_wait} retournera seulement $N$ fois de plus que
    \texttt{sem\_signal} appelé
  \ittms{
    \item Exemple :  Si $N==1$, alors le sémaphore est un mutex avec
      \texttt{sem\_wait} comme verrou et \texttt{sem\_signal} comme déverrouillage
  }
  \item Les sémaphores donnent des solutions élégantes à certains problèmes
  \item Linux utilise principalement des sémaphores pour les verrous dormants
  \ittms{
    \item \texttt{sema\_init}, \texttt{down\_interruptible},
      \texttt{up}, \ldots
%\item Also weird reader-writer semaphores, \texttt{rw\_semaphore}
%  \href{http://www.linuxjournal.com/article/5833}{[Love]}
% Seems abstractions called "lock" in the linux kernel are all
% spinlocks.  So they are using semaphores as sleeping locks.
    \item Mais les preuves pourraient favoriser
      les mutex~\href{http://www.kernel.org/doc/Documentation/mutex-design.txt}{[Molnar]}
  }
}
\end{slide}

\begin{frame}[fragile]
\frametitle{Producteur/Consommateur avec sémaphores}
\itms{
  \item Initialiser \texttt{nonempty} à 0 (bloque le consommateur quand le buffer est vide)
  \item Initialiser \texttt{nonfull} à $N$ (bloque le producteur quand la file est pleine)
}
\begin{smallccode}[classoffset=2,morekeywords={sem_wait,sem_signal},keywordstyle=\color{red}]
     void producer (void *ignored) {
         for (;;) {
             item *nextProduced = produce_item ();
             sem_wait (&nonfull);
             buffer [in] = nextProduced;
             in = (in + 1) % BUFFER_SIZE;
             sem_signal (&nonempty);
         }
     }
     void consumer (void *ignored) {
         for (;;) {
             sem_wait (&nonempty);
             item *nextConsumed =  buffer[out];
             out = (out + 1) % BUFFER_SIZE;
             sem_signal (&nonfull);
             consume_item (nextConsumed);
         }
     }
\end{smallccode}
\end{frame}


\begin{slide}{Autres fonctionnalités des bibliothèques de threads}
\itms{
  \item Alertes -- provoque une exception dans un thread
  %\item Trylock -- don't block if can't acquire mutex
  \item Timedwait -- délai d'attente sur variable de condition
  \item Verrous partagés -- accès concurrents en lecture aux données
  \item Priorités de thread -- contrôle la politique d'ordonnancement
  \ittms{
    \item Les attributs de mutex permettent diverses formes de \emph{donation de
        priorité} \\
      (concept familier après le lab 1)
  }
  \item Stockage local au thread (TLS)
}
\end{slide}

\defverbatim[colored]\muteximp{
\begin{smallccode}[classoffset=2,morekeywords={lower_level_lock_t,lk},
        keywordstyle=\color{red}]
    typedef struct mutex {
      bool is_locked;            /* true if locked */
      thread_id_t owner;         /* thread holding lock, if locked */
      thread_list_t waiters;     /* threads en attente du verrou */

      lower_level_lock_t lk;     /* Protect above fields */
    };
\end{smallccode}
}

\begin{frame}
\frametitle{Implémenter la synchronisation}
\itms{
  \item Le mutex visible par l'utilisateur est une structure de données simple
\muteximp
  \item Besoin d'un verrou de bas niveau \texttt{lk} pour l'exclusion mutuelle
  \ittms{
    \item En interne, les fonctions \texttt{mutex\_*} encadrent le code avec \\
\texttt{lock(mutex->lk)} \ldots\ \texttt{unlock(mutex->lk)}
    \item Sinon, \emph{race conditions} !
    (Ex : deux threads manipulant \texttt{waiters})
  }
  \item \Red{Comment implémenter \texttt{lower\_level\_lock\_t} ?}
  \ittms{
    \item Utiliser le support matériel pour la synchronisation
  }
}
\end{frame}

\begin{slide}{Approche \#1 : Masquer les interruptions}
\itms{
  \item Seulement pour les apps avec $n:1$ threads (1 kthread)
  \ittms{
    \item Ne peut pas tirer parti des multiprocesseurs
    \item Mais parfois la solution la plus efficace pour les uniprocesseurs
  }
  \item \hypertarget{DNI}Avoir un bit « ne pas interrompre » (DNI) par thread
  \item \texttt{lock (lk)} : active le bit DNI du thread
  \item Si une interruption timer arrive
  \ittms{
    \item Vérifier le bit DNI du thread interrompu
    \item Si DNI inactif, préempter le thread courant
    \item Si DNI actif, activer le bit « interrompu » (I) \& reprendre le thread
      courant
  }
  \item \texttt{unlock (lk)} : désactive le bit DNI \emph{et} vérifie le bit I
  \ittms{
    \item Si le bit I est actif, cède immédiatement le CPU
  }
}
\end{slide}

\defverbatim\spinlock{
\begin{ccode}
     #define lock(lockp)    while (test_and_set (lockp))
     #define trylock(lockp) (test_and_set (lockp) == 0)
     #define unlock(lockp)  *lockp = 0
\end{ccode}}

\begin{frame}
\frametitle{Approche \#2 : \emph{Spinlocks}}
\itms{
  \item La plupart des CPU supportent lecture-[modification-]écriture atomique
  %\item Most CPUs have atomic read-write or atomic read-modify-write
  \item Exemple :  \texttt{int test\_and\_set (int *lockp);}
  \ittms{
    \item Met atomiquement \texttt{*lockp = 1} et retourne l'ancienne valeur
    \item Instruction spéciale -- ne peut être implémentée en C portable
    }
  \item Utiliser cette instruction pour implémenter des \emph{spinlocks} :
\spinlock
  \item Les \emph{spinlocks} implémentent le \texttt{lower\_level\_lock\_t} du mutex
  \item Utiliser des \emph{spinlocks} au lieu des mutex ?
  \ittms{
    \item Gaspillage de temps CPU et énérgie
    \item Les fonctions mutex ont des S.C. courtes, moins de risque de préemption
    \item Sur multiprocesseur, tourner un peu puis préempter
  }
%  \item But gratuitous context switch has cost
%  \ittms{
%    \item On MP, sometimes good to spin for a bit, then yield
%  }
}
\end{frame}

%\begin{slide}{Synchronization on x86}
%\itms{
%  \item Test-and-set only one possible atomic instruction
%  \item x86 \texttt{xchg} instruction, exchanges reg with mem
%  \ittms{
%    \item Can use to implement test-and-set
%  }
%}
%\begin{asm}
%        _test_and_set:
%                movl    8(%esp), %edx   # %edx = lockp
%                movl    $1, %eax        # %eax = 1
%                xchgl   %eax, (%edx)    # swap (%eax, *lockp)
%                ret
%\end{asm}%$
%\itms{
%  \item CPU locks memory system around read and write
%  \ittms{
%    \item Recall \texttt{xchgl} always acts like it has \texttt{lock} prefix
%    \item Prevents other uses of the bus (e.g., DMA)
%  }
%  \item Usually runs at memory bus speed, not CPU speed
%  \ittms{
%    \item Much slower than cached read/buffered write
%  }
%}
%\end{slide}

\defverbatim[colored]\splhigh{
\begin{ccode}
    int x = splhigh ();   /* Disable interrupts */
    /* touch data shared with interrupt handler ... */
    splx (x);             /* Restore previous state */
\end{ccode}
}

%\begin{frame}
%\frametitle{Kernel Synchronization}
%\itms{
%  \item \Red{Should kernel use locks or disable interrupts?}
%  \item Old UNIX had non-preemptive threads, no mutexes
%  \ittms{
%    \item Interface designed for single CPU, so \texttt{count++} etc.\ not data race
%    \item
%    \ldots\emph{Unless} memory shared with an interrupt handler
%    \\[1ex]
%    \splhigh
%    \item C.f.,
%      \cref{pintos/pintos_6.html\#SEC101}{Pintos}
%      \texttt{intr\_disable} / \texttt{intr\_set\_level}
%  }
%  \item Used arbitrary pointers like condition variables
%  \ittms{
%    \item \texttt{int [t]sleep (void *ident, int priority, ...);} \\
%      put thread to sleep; will wake up at \texttt{priority}
%      ($\sim$\texttt{cond\_wait})
%    \item \texttt{int wakeup (void *ident);} \\
%      wake up all threads sleeping on \texttt{ident}
%      ($\sim$\texttt{cond\_broadcast})
%  }
%}
%\end{frame}

%\begin{slide}{Kernel locks}
%\itms{
%  \item Nowadays, should design for multiprocessors
%  \ittms{
%    \item Even if first version of OS is for uniprocessor
%    \item Someday may want multiple CPUs and need \emph{preemptive}
%      threads
%    \item That's why Pintos uses locks
%  }
%  \item Multiprocessor performance needs fine-grained locks
%  \ittms{
%    \item Want to be able to call into the kernel on multiple CPUs
%  }
%  \item \Red{If kernel has locks, should it ever disable interrupts?}
%\pause
%  \ittms{
%    \item Yes!  Can't sleep in interrupt handler, so can't wait for lock
%    \item So even modern OSes have support for disabling interrupts
%    \item Often uses \hyperlink{DNI}{DNI} trick, which is cheaper than masking
%      interrupts in hardware
%  }
%}
%\end{slide}

%% \begin{slide}{UNIX Synchronization 2}
%% \itms{
%%   \item Need to relinquish CPU when waiting for events
%%   \ittms{
%%     \item Disk read, network packet arrival, pipe write, signal, etc.
%%   }
%%   \item \texttt{int tsleep(void *ident, int priority, ...);}
%%   \ittms{
%%     \item Switches to another process
%%     \item \texttt{ident} is arbitrary pointer---e.g., buffer address
%%     \item \texttt{priority} is priority at which to run when woken up
%%     \item \textsc{PCATCH}, if ORed into \texttt{priority}, means wake
%%           up on signal
%%     \item Returns 0 if awakened, or \textsc{ERESTART}/\textsc{EINTR} on
%%           signal
%%   }
%%   \item \texttt{int wakeup(void *ident);}
%%   \ittms{
%%     \item Awakens all processes sleeping on \texttt{ident}
%%     \item Restores SPL to value when they went to sleep \\
%%       (so fine to sleep at splhigh)
%%   }
%% }
%% \end{slide}


%% \begin{slide}{Monitors
%%     [BH]\cref{sched/readings/monitors.pdf}{[Hoar]}}
%% \itms{
%%   \item Programming language construct
%%   \ittms{
%%     \item Possibly less error prone than raw mutexes, but less flexible too
%%     \item Basically a class where only one procedure executes at a time
%%   }
%% }
%% \begin{ccode}
%%           monitor monitor-name
%%           {
%%             // shared variable declarations
%%             procedure P1 (...) { ... }
%%             ...
%%             procedure Pn (...) { ... }

%%             Initialization code (..) { ... }
%%           }
%% \end{ccode}
%% \itms{
%%   \item Can implement mutex w.\ monitor or vice versa
%%   \ittms{
%%     \item But monitor alone doesn't give you condition variables
%%     \item Need some other way to interact w.\ scheduler
%%     \item Use \emph{conditions}, which are essentially condition variables
%%   }
%% }
%% \end{slide}

%% \begin{slide}{Monitor implementation}
%% \centerline{\includegraphics[height=2.2in]{figs/monitorcond}}
%% \medskip
%% \itms{
%%   \item Queue of threads waiting to get in
%%   \ittms{
%%     \item Might be protected by spinlock
%%   }
%%   \item Queues associated with conditions
%% }
%% \end{slide}
\end{document}

\begin{slide}{Problème Lecteurs-Rédacteurs}
\itms{
  \item Plusieurs threads peuvent accéder aux données
  \ittms{
    \item \emph{Lecteurs} -- vont seulement observer, pas modifier les données
    \item \emph{Rédacteurs} -- vont changer les données
  }
  \item But : autoriser plusieurs lecteurs ou un seul rédacteur
  \ittms{
    \item Ainsi, le verrou peut être \emph{partagé} entre les lecteurs concurrents
  }
  \item Peut être implémenté avec d'autres primitives
  \ittms{
    \item Garder un entier \texttt{i} -- \# de lecteurs ou -1 si tenu par un rédacteur
  }
}
\end{slide}

\begin{slide}{Implémenter les verrous partagés}
\vspace*{-2ex}
\begin{myverb}
struct sharedlk {
  int i;
  mutex_t m;
  cond_t c;
};

void AcquireExclusive (sharedlk *sl) {
  lock (sl->m);
  while (sl->i) { wait (sl->m, sl->c); }
  sl->i = -1;
  unlock (sl->m);
}

void AcquireShared (sharedlk *sl) {
  lock (sl->m);
  while (sl->i < 0) { wait (sl->m, sl->c); }
  sl->i++;
  unlock (sl->m);
}
\end{myverb}
\end{slide}

\begin{slide}{verrous partagés (suite)}
\begin{myverb}
void ReleaseShared (sharedlk *sl) {
  lock (sl->m);
  if (!--sl->i) signal (sl->c);
  unlock (sl->m);
}

void ReleaseExclusive (sharedlk *sl) {
  lock (sl->m);
  sl->i = 0;
  broadcast (sl->c);
  unlock (sl->m);
}
\end{myverb}
\itms{
  \item Note : Doit gérer la famine
}
\end{slide}

\end{document}



\begin{slide}{\textit{Race Conditions} Bénignes}
\itms{
  \item Parfois « tricher » achète de l'efficacité\ldots
  \item Se soucier plus de la vitesse que de la précision
}
\begin{myverb}
    hits++;  // chaque fois que quelqu'un accède au site web
\end{myverb}
\itms{
  \item Savoir qu'on peut s'en tirer avec une \emph{race condition}
}
\begin{myverb}
    if (!initialized) {
      lock (m);
      if (!initialized) { initialize (); initialized = 1; }
      unlock (m);
    }
\end{myverb}
\end{slide}

\begin{slide}{Détecter les \textit{Race Conditions}}
\itms{
  \item Méthodes statiques (dur)
  \item Débogage pénible---la \emph{race} peut survenir rarement
  \item Instrumentation---modifier le programme pour piéger les accès mémoire
  \item L'algorithme Lockset (eraser) particulièrement efficace :
  \ittms{
    \item Pour chaque emplacement mémoire global, garder un « lockset »
    \item À chaque accès, retirer tout verrou non détenu actuellement
    \item Si le lockset devient vide, avorter : Aucun mutex ne protège la donnée
    \item Attrape les \emph{races} potentielles même si elles ne se produisent pas
  }
}
\end{slide}



\end{document}
